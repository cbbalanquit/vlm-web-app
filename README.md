# VLM Demo
This project is a demo of the VLM (Video Language Model) model. The VLM model is a multimodal model that combines video and text data to generate video descriptions. 

## How to run the project
1. Clone the repository
2. Install `uv` package manager
3. Ensure to add environment variable `GPU_INDEX=<desired_index>` to use the appropriate GPU
4. Run `uv run run.py`
5. Go to the application url using your browser
6. Allow the application to access your camera